12.1 https://www.nowcoder.com/discuss/571830  	未完成
12.2 https://www.nowcoder.com/discuss/574278	未开始

Java基础

1. 8种基本数据类型和长度
	bool	1B	true or false
	byte	1B	-128 ~ 127
	short	2B	-32768~32767  -2^(n-1) ~ 2^(n-1)-1
	char	2B	0~65535
	int		4B	-2147483648~2147483647 -2^31 ~ 2^31-1
	float	4B 	-3.4E38~3.4E38
	long	8B	-9223372036854775808 ~ 9223372036854775807
	double	8B	-1.7E308~1.7E308

2. hashmap的内容
	数组+链表 JDK1.8有改变,当链表长度大于8并且数组的bin超过64时,会将链表转化为红黑树 key value键值对
	hash操作
		1.8之后 用hash值的前16位和后16位做异或增大扰动性,就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。
		而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来
		主要是高位不同, 低位相同导致的hash冲突. 因为hashmap的数组长度有限,防止一直mod取的低位数字
		return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
	put操作
		经过hash = key & (2^n-1) 定位到数组位置
			如果数组位置没有元素就直接插入
			如果定位到的数组位置有元素,遍历这个元素为头结点的链表依次和插入的key比较(equals),如果key相同则覆盖;
				不相同,判断p是否是一个树节点:是树节点就调用红黑树的putTreeVal将元素插入;是链表的话就遍历链表(插入的链表尾部)
		对应扩容, 转为红黑树
	resize
	get
	版本1.8之前之后
		
3. ArrayList
	扩容:
		一开始默认为容量为10 只有在add的时候才进行初始化 到11是才开始扩容
		newCapacity = oldCapacity + (oldCapacity >> 1) 每次扩容为原来的1.5倍
		System.arraycopy(elementData, index, elementData, index + 1, size - index) 函数进行拷贝
		并不会自动锁容,但是可以调用trimToSize()方法手动缩容
		
4. Object类的方法
	1. equals() 方法
		1)equals默认是比较对象地址是否相同 如果是同一个对象返回true
		2)重写判断内容是否相同: 同一个类的对象/成员变量都相同
		3)满足的性质: x.equals(null) false
				自反性: 非空x x.equals(x) true
				对称性: x,y非空 x.equals(y) 同时 y.equals(x)为true
				传递性：x.equals(y) 返回 true，y.equals(z) 返回 true，x.equals(z) 也应该返回 true
				一致性：如果 x 和 y 引用的对象没有发生变化，反复调用 x.equals(y) 应该返回相同的结果
	2. getClass() 方法
	3. hashCode() 方法
	4. finalize() 方法
	5. clone() 方法
	6. toString() 方法
		
		
数据结构与算法

1. 数组，链表插入性能对比
	对于数组,根据索引获得插入位置的时间复杂度是O(1) 
	但是插入数据时需要移动数据 
		在数组头插入 最坏复杂度是O(n) 
		在数组末尾插入 最好O(1)
		平均复杂度O(n)
	对于链表 内存地址不连续 通过指针/引用找到下个节点的位置
		查找数据插入位置所需要的时间
			最好情况是在链表头 O(1)
			最差情况是在链表尾找到O(n)
			平均复杂度O(n)
		但是插入数据很简单 只需要O(1)
		

2. bloom filter 布隆过滤器
	是一种数据结构,用来判某样东西一定不存在或者可能存在,用来检测一个元素是否在一个集合中更高效,占用小,
	优点是空间效率和查找效率远超普通的set map数据结构, 
	缺点:	返回的结果是概率性的,不是确切的 可能会判断失误
	结构:	一个很长的bit二进制数组bitmap + 一系列随机映射hash函数组成
	应用: 	黑名单系统, 垃圾邮件过滤系统, 爬虫网址判重系统 
			尤其在数据量上亿的时候 数据库承受不住
	原理:	bitmap的长度设为m k个互相独立的哈希函数 
			每个hash函数都把输入元素 映射到[0, m-1] 上 得到k个数 将k个数对应到bitmap上标记为1
			判断时:计算输入元素的k个数 
				如果bitmap中的这k个数对应的bit有一个不为 1 说明这个元素不在集合中
				如果全为 1 说明有一定概率在集合中 不能完全确定 
			错误率和bitmap的长度m 元素个数n hash函数个数k有关
	概率: https://www.zhihu.com/search?type=content&q=%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%20%E6%A6%82%E7%8E%87%E8%AE%A1%E7%AE%97
		对于特定位 没有被置为1的概率(1 - 1/m) k个函数之后仍然为0的概率(1-1/m)^k
		对于n个元素输入之后仍然为0的概率(1-1/m)^(kn) 为1的概率就是(1 - (1-1/m)^(kn)); e = lim(1+1/n)^n , n->无穷
		假设某个元素不在集合里 但是算出的k个位置都为1的概率就是 (1 - (1-1/m)^(kn) = (1 - e^(-kn/m))^k
		错误率最小 False positive k = (m/n)*ln2

3. b+ tree 和b tree 区别
	为了减少硬盘索引的读取次数 不采用二叉搜索树 而是多路平衡树,减少树的高度 高度小磁盘读写次数少,提升了性能
	B 树 多路平衡查找树 参数: m阶
		1. 根节点至少有两个孩子, 除非他是叶子节点
		2. 每个中间节点都包含 k-1 个元素 和 k个分支 其中 ceil(m/2) <= k <= m
		3. 每个叶子节点都包含 k-1 个元素,并且叶子节点不包含任何关键字信息 即为null 其中 ceil(m/2) <= k <= m
		4. 每个非终端结点中包含有n个关键字信息： (P1，K1，P2，K2，P3，......，Kn，Pn+1)。其中：
			a)   Ki (i=1...n)为关键字，且关键字按顺序升序排序K_(i-1)< K_i。 
			b)   Pi为指向子树根的接点，且指针P(i)指向子树种所有结点的关键字均小于Ki，但都大于K(i-1)。 
			c)   关键字的个数n必须满足： [ceil(m / 2) - 1] <= n <= m-1。
		操作: 插入操作的时候, 可能会向上分裂; 删除操作的时候可能会需要向左或者向右借节点 合并再删除
		
	B+树 m阶
		1. 有k个子树的中间节点包含有k个关键字(B树有k-1个关键字,非根节点元素范围 ceil(m/2) <= k <= m-1
		2. 所有叶子节点包含了全部关键字的信息,叶子节点本身依靠关键字大小排序
		3. 所有的非终端节点都可以看做是索引部分, 节点中仅包含子树根节点中最大(最小)关键字
		4. 叶子节点之间有指针
	B+树 优势
		1. 单一节点存储更多地元素 使得查询的IO次数更少
			因为B树不管叶子节点还是非叶子节点，都会保存数据, 这样导致在非叶子节点中能保存的指针数量变少
			指针少树的高度会增加,导致IO变多,性能变低
		2. 所有的查询都要查找到叶子节点, 查询性能稳定
		3. 所有叶子节点形成有序列表,便于范围查询
	

	
5. top - k小元素

6. 红黑树

7. KMP

8. 排序 堆排序



设计模式
1.单例模式
	定义:单例模式是指在内存中只会创建且仅创建一次对象的设计模式。
		 在程序中多次使用同一个对象且作用相同时，为了防止频繁地创建对象使得内存飙升.
		 单例模式可以让程序仅在内存中创建一个对象，让所有需要调用的地方都共享这一单例对象。
	类型:
		懒汉式: 在真正需要的时候比如调用的时候才去创建该类对象
				比如说一个对象使用频率不高,占用内存很大的时候
		饿汉式: 在类加载的时候就直接创建该单例对象
	写法:
		public class Singleton {	
			private static volatile Singleton singleton;
			private Singleton(){}
			public static Singleton getInstance() {
				if (singleton == null) {  // 线程A和线程B同时看到singleton = null，如果不为null，则直接返回singleton
					synchronized(Singleton.class) { // 线程A或线程B获得该锁进行初始化
						if (singleton == null) { // 其中一个线程进入该分支，另外一个线程则不会进入该分支
							singleton = new Singleton();
						}
					}
				}
				return singleton;
			}
		}
	双重校验锁DCL解释:
		1. 懒汉模式: 需要的时候才创建
		2. synchronized 加锁 为了并发 防止同时创建对象
		3. 双重检验 - 判断是否为null 每次获取对象都要获取锁,并发性能比较差;
			如果不是null的话直接得到对象,解决了并发安全+性能低效问题
		4. volatile 防止指令重排
			JVM内存分配:
				1)为singleton分配内存空间
				2)初始化singleton对象
				3)将singleton指向分配好的内存空间
			JVM在保证最终结果正确的情况下，可以不按照程序编码的顺序执行语句，尽可能提高程序的性能
			第2, 3步有可能发生重排, 1-3-2导致虽然此时singleton对象已经指向了分配好的内存空间,不为null
				但是还没有初始化,导致空指针异常
				
				

数据库
关系型数据库（主要为 Mysql）

简述关系型数据库与菲关系形数据库的区别与联系
简述数据库的事务
数据库三范式
分别说一下范式和反范式的优缺点
Mysql 数据库索引。B+ 树和 B 树的区别
为什么 B+ 树比 B 树更适合应用于数据库索引，除了数据库索引，还有什么地方用到了（操作系统的文件索引）
聚簇索引和非聚簇索引
前缀索引和覆盖索引
介绍一下数据库的事务
Mysql 有哪些隔离级别
Mysql 什么情况会造成脏读、可重复度、幻读？如何解决
Mysql 在可重复度的隔离级别下会不会有幻读的情况，为什么？
Mysql 事务是如何实现的
Binlog 和 Redo log 的区别是什么，分别是什么用？
谈一谈 MVCC 多版本并发控制
Innodb 和 MyISAM 的区别是什么
Innodb 的默认加锁方式是什么，是怎么实现的
如何高效处理大库 DDL
Mysql 索引重建
对于多列索引，哪些情况下能用到索引，哪些情况用不到索引
为什么使用数据库索引可以提高效率，在什么情况下会用不到数据库索引？
共享锁和排他锁的使用场景，
关系型数据库和非关系数据库的优缺点
Mysql 什么情况会造成慢查，如何查看慢查询
如何处理慢查询，你一般是怎么处理慢查询的
Mysql 中 varchar 和 char 的区别
数据库外键的优缺点
有没有使用过数据库的视图
Mysql 中插入数据使用自增 id 好还是使用 uuid，为什么？
Mysql 有哪些数据类型，使用的时候有没有什么注意点
Mysql 集群有哪几种方式，分别适用于什么场景
Mysql 主从模式如何保证主从强一致性
Mysql 集群如何保证主从可用性
Mysql 读写分离有哪些解决办法

非关系型数据库
redis 的底层数据结构有哪些
redis 中的 SDS 和 C 语言中的字符串有什么区别，优点是什么
redis 中的字典是如何实现的，如何解决冲突和扩容
redis 的跳表的使用场景是什么，可以实现一下吗
redis 缓存穿透，缓存击穿，缓存雪崩，热点数据集中失效 （常问）
redis 的淘汰策略，来写一下 LRU 吧
redis 的持久化方式，RDB 和 AOF 分别的使用场景
redis 如何处理事务
redis 为什么那么快？
redis 是单线程为什么还那么快？
redis 的操作为什么是原子性的，如何保证原子性
redis 集群用过哪些方案，分别怎么做。讲一下一致性哈希
redis 什么情况下会出现性能问题，有什么处理办法？
有没有使用过 redis 的分布式锁，有什么优缺点
说一下 redis 的内存模型
说一下 redis 和 memcache 的区别
你用 redis 做过什么？（这里尽量不要讲只做过缓存，可以说一下队列，排行榜/计数器，发布/订阅）
你用过哪些非关系型数据库，都有什么特点，使用场景分别是什么（体现你技术广度的时刻到了，尽可能多说，但是不会的不要说，防止被问死）
Mongodb 相对于 Mysql 有哪些优势，底层索引使用的数据结构是什么，为什么要使用这个
Mongodb 中的分片是什么意思


计算机网络
1. TCP为什么是三次握手, 四次挥手?
	a.服务器一直处于监听状态
		第一次握手:
			主机A发送SYN=1 seq=x的数据包到服务器B, 主机B由syn=1知道, A要建立联机 ACK=0
		第二次握手:
			主机B收到请求后,要求确认联机,向A发送ACK=1 ack=x+1 | SYN=1  seq=y 
		第三次握手
			主机A发送ACK=1 ack=y+1 | seq=x+1
			主机A收到报文段, 检查sck number是否正确, 第一次的x+1 以及ACK是否为1
		ack是期望收到对面字节数据的下一个序号; seq序号是己方字节数据的第一个字节的序号,保证TCP传输的有序性,防止重复接受处理
	b.为什么三次挥手
		主机A会发送连接请求,但是没有收到确认,于是重新发送了连接请求;服务器收到了请求并且接受连接,发出确认同意建立连接,数据传输完毕正常释放;
		此时因为网络延迟,服务器收了A的第一次请求.
		如果两个挥手的话,服务会收到主机流浪在网络中的请求连接,那么服务器就会直接同意建立连接;
		而此时主机A早已关闭,服务会浪费资源
		
	c.四次挥手
		1)客户端 发送FIN = 1 seq = u 用来关闭客户端到服务器的数据传输
		我的序号是u(u就是之前传送过的所有数据的最后一个字节的序号+1)
		2)服务器收到FIN 发回一个ACK=1 seq=v ack number = u+1
		这条消息的序号是v（seq=v ，这是服务器发送消息的序号)
	d.服务器close_wait: 此时,客户端通往服务器的路断开了,客户端不能向服务器发送数据
		3) 服务器关闭与客户端的连接 发送一个FIN = 1, ACK = 1, seq= w, ack number = u + 1
			这中间服务器可能又继续发送了一些数据，可能是v+1 也可能发送了更多，所以设置为w
			ACK=1，ack=u+1，因为客户端已经不能发送数据了，服务器期望收到的序号永远都是最后一个序号+1，也就是u+1
		4)客户端发回ACK报文确认, ACK=1 ack=w+1 seq=u+1并将确认序号+1
	e.客户端Time_wait:等待2MSL报文最大生存时间之后关闭
			确保最后一个确认报文到达服务器. 如果B没有收到A的确认报文, 就会重新发送确认报文
				消息发出来谁知道别人收没收到，所以还需要一个确认
			让本连接持续时间段内产生的报文都从网络消失,不影响下一个新的连接请求报文
	f.为什么四次挥手:
		关闭连接时, Serve端收到FIN报文时, 很可能不会立即断开SOCKET,所以先回复一个ACK表示知道了
			服务器还有数据要发,和打电话一样,你说完了但是我还没有说完
		只有等到Serve端将报文都发送完时,服务器才会发送FIN报文,表明数据都传送完了


2. HTTPS 和 HTTP 的区别
	1)HTTP（超文本传输协议）的基础上再加一层TLS（传输层安全性协议）或者SSL（安全套接层）
		HTTP协议运行在TCP之上，所有传输的内容都是明文，HTTPS运行在SSL/TLS之上，SSL/TLS运行在TCP之上，所有传输的内容都经过加密的。
		HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源
	2)HTTPS 用非对称加密传输对称加密钥匙,非对称加密的缺点就是运算速度非常慢
	3)HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
	4)HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。
	
3. HTTPS加密过程？对称加密非对称加密？
	a.对称加密: 加密和解密的密钥是一样的
		AES 加密函数为E 密文=E(明文, 密钥)
			解密函数为D 明文=D(密文, 密钥)
		解密过程仍为10轮，每一轮的操作是加密操作的逆操作。由于AES的4个轮操作都是可逆的，
		因此，解密操作的一轮就是顺序执行逆行移位、逆字节代换、轮密钥加和逆列混合。同加密操作类似，最后一轮不执行逆列混合，在第1轮解密之前，要执行1次密钥加操作
	
	b.非对称加密: 加密和解密的密钥是不一样的 
		RSA基于大数分解
		https://zh.m.wikipedia.org/zh-sg/RSA%E5%8A%A0%E5%AF%86%E6%BC%94%E7%AE%97%E6%B3%95

		
	c.CA: Certificate Authority
		负责对证书进行签名 CA用自己私钥进行签名,客户端用公钥解密验证Hash值是否一致
	d.加密过程:
		1)客户端发起一个http请求(三次握手)，连接到服务器的443端口 
			HTTP协议
		2)服务端把自己的信息以数字证书的形式返回给客户端(证书内容有密钥公钥，网站地址，证书颁发机构，失效日期等)。
			证书中有一个公钥来加密信息，私钥由服务器持有。
		3)客户端验证证书的合法性客户端验证证书是否合法，如果不合法则提示告警
			客户端收到服务器的响应后会先验证证书的合法性（证书中包含的地址与正在访问的地址是否一致，证书是否过期）。
		4)生成随机密码,用RSA签名
			如果验证通过，或用户接受了不受信任的证书，浏览器就会生成一个随机的对称密钥(session key)
			并用公钥加密，让服务端用私钥解密，解密后就用这个对称密钥进行传输了，并且能够说明服务端确实是私钥的持有者。
		5)生成对称加密算法
			验证完服务端身份后，客户端生成一个对称加密的算法和对应密钥，以公钥加密之后发送给服务端。
			此时被黑客截获也没用，因为只有服务端的私钥才可以对其进行解密。之后客户端与服务端可以用这个对称加密算法来加密和解密通信内容了。

4. cookie与session
	cookie
		1)http是无状态的协议，客户每次读取web页面时，服务器都打开新的会话，而且服务器也不会自动维护客户的上下文信息
		2)Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。
		3)客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。
		4)服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。
		5)session id存放在cookie中, 加密
		6)第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie 里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，
		7)如果客户端的浏览器禁用了 Cookie 会使用一种叫做URL重写的技术来进行会话跟踪，
			即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数，服务端据此来识别用户。
	session
		1)Session是一种记录客户状态的机制，不同于Cookie的是Cookie保存在客户端浏览器中，而Session保存在服务器上。
		2)客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上,这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。
	区别:
		Session工作在Server中；Cookie工作在Client
		二者均工作在内存中，也可以做持久化
		

DNS劫持是什么，怎么解决
TCP 和 UDP 的区别，为什么头部长度不一样？
简述从输入网址到浏览器显示的过程
TCP 如何保障数据包有效


操作系统
1. 进程, 线程, 协程
	进程
	- 进程是操作系统进行资源分配的基本单位, 进程拥有自己的资源空间,包含若干线程
	- 进程是操作系统结构的基础
	- 系统进行资源分配和调度的独立单位
	线程
	- 线程是调度的基本单位, 线程的调度比进程要快
	- 进程中独立运行的子任务
		线程的创建和切换开销比进程小
		进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率
		终止一个线程要比终止一个进程花费的时间少 线程间切换也比进程间切换要花费少
		线程提高了不同执行程序之间的通信效率,线程在同一个进程中的线程共享内存和文件
	协程
		进程和线程受os调度算法的影响,无法精确控制
		协程（Coroutine）是一种轻量级的用户态线程，实现的是非抢占式的调度，即由当前协程切换到其他协程由当前协程来控制
			协程执行不下去的时候,自己通知协程池调度器,主动让出CPU
			切换这个协程的CPU上下文把CPU的运行权交给下一个协程
		优点:
			协程更加轻量，创建成本更小，降低了内存消耗
			协作式的用户态调度器，减少了 CPU 上下文切换的开销，提高了 CPU 缓存命中率。
			进程 / 线程的切换需要在内核完成，而协程不需要，协程通过用户态栈实现，更加轻量，速度更快。在重 I/O 的程序里有很大的优势
			减少同步加锁，整体上提高了性能。协程方案基于事件循环方案，减少了同步加锁的频率。
				但若存在竞争，并不能保证临界区，因此该上锁的地方仍需要加上协程锁
			可以按照同步思维写异步代码，即用同步的逻辑，写由协程调度的回调
		缺点:
			在协程执行中不能有阻塞操作，否则整个线程被阻塞(协程是语言级别的，线程，进程属于操作系统级别)
			需要特别关注全局变量、对象引用的使用
			协程可以处理 IO 密集型程序的效率问题，但是处理 CPU 密集型不是它的长处
		用处:
			高性能计算，牺牲公平性换取吞吐
			
2. 进程通信
	管道
		是指用于连接一个读进程和一个写进程以实现他们之间通信的一个共享文件——.pipe文件。
		写进程向管道以字符流写入数据，读进程从管道中接收输出。管道必须提供同步、互斥并能确定对方存在的方法
		netstat -tulnp | grep 8080
		匿名管道 
			单向 第一个的输出作为第二个的输入
		命名管道
			mkfifo  test 
			双向的 一个写了之后第二个去拿 类似缓存
			效率低下 只有拿完才返回
		不适合频繁通信的进程
	共享内存
		通过一片共享区域进行读写操作实现进程之间的信息交换。在操作时需要使用同步互斥工具(PV操作)。共享存储分为低级的基于数据结构的共享和高级的基于存储区的共享
	信号量机制
		信号量的本质就是计数器，在访问临界资源并进入临界区时，使用os提供的PV操作对计数器进行修改
	消息队列
	消息传递		
		利用os提供的发送原语和接收原语进行交换
		消息传递分为直接通信和间接通信。
			直接通信采用进程间发消息的方式，将消息挂在接收进程的消息缓冲队列上，接收进程从该队列上取得消息。
			间接通信则将消息发送到某个中间实体上，称其为信箱。

	Socket
		接字也是一种进程间通信机制，与其它通信机制不同的是，它可用于不同机器间的进程通信
		
3. 线程状态, 线程上下文切换？
	Java	线程状态 抢占式调度
	1.新建状态
		new完一个线程对象之后, 处于新建状态
	2.就绪状态
		调用start()方法之后, 该线程就进入就绪状态(就绪队列中) 等待JVM里线程调度器的调度
	3.运行状态
		执行run() 此时线程处于运行状态. 可以转换成 -> 阻塞状态/就绪状态/死亡状态
	4.阻塞状态
	如果一个线程执行了sleep睡眠 suspend挂起等方法 失去所占资源之后,该线程就从运行状态转化为阻塞状态
	5.死亡状态
		完成任务或者终止条件发生
	一些方法
	sleep(): 让当前线程睡眠 不会释放任何锁
	yield(): 让出时间片给其他线程,回到就绪状态. 
			 线程调度重新选择就绪态的线程分配CPU资源
	join():  暂停当前线程,等待被调用的线程指向结束后再继续执行
	wait(): 让该线程处于等待状态 会释放掉CPU执行权和占用的锁
			不能自动唤醒,依靠其他线程调用notify() 或者notifyAll()方法才能被唤醒
		
4. 进程调度说说吧？讲讲进程调度算法？
	进程的数量是远多于处理器数量的,因此宏观上并行的进程在微观上往往属于分时复用.
	进程调度的本质就是怎么更好分时复用处理器资源, 包括调度策略和进程切花
	指标: 周转时间(运行时间Ts+等待时间Tw = 执行完成时间-到达时间) T
			带权周转时间(周转时间T / 执行时间Ts)
	常用调度算法:
		1.先来先服务FCFS:
			1)按照作业提交的时间先后顺序,或者进程变为就绪态的先后次序分派CPU
			2)只有当前进程执行完成或者阻塞,新的进程才获得CPU运行
			3)默认非抢占,被唤醒的作业或者进程不立即恢复执行,通常等到当前作业出让CPU
			4)有利于CPU繁忙型作业,不利于IO繁忙的进程
			5)不利于短作业进程(需要等待较长时间 但是运行时间很短 带权周转时间很大)
			
		2.短作业（进程）优先调度算法SJF（非抢占）/SPF（抢占）
			1)从后备队列中选出一个或者若干个估计运行时间最短的作业,调入内存运行
			2)平均周转时间、平均带权周转时间都有明显改善,有效的降低作业的平均等待时间，提高系统吞吐量。
			3)未考虑作业的紧迫程度，因而不能保证紧迫性作业（进程）的及时处理、
			4)对长作业的不利、长作业的周转时间明显增加。
			5)必须知道作业运行时间, 作业（进程）的长短含主观因素, 不一定真的能做到短作业优先
			
		3.时间片轮转
			1)排成一个队列,每次调度时将CPU分配给队首
			2)为每个进程分配一个固定的时间片段,时间片运转完,进行进程切换
			3)当前进程阻塞或者已经执行完成 未用完的时间片也要让出CPU
			4)响应及时, 但是没有考虑作业时间长短问题,
			5)需要考虑时间片的长度,影响比较大
			
		4.多级反馈队列调度算法
			1)设置多个就绪队列,分别赋予不同的优先级,优先权逐级降低,但是优先级越低分配的时间片越长,例如逐级加倍
			2)新进程进入内存后,加入队列1的末尾 按FCFS算法进行调度 如果队列1时间片未能执行完毕,则降低优先级加入到队列2的末尾;
				依次类推直到最后的队列,则按时间片轮转运行完毕
			3)仅当高优先级队列为空时,才调度低优先级队列的进程执行;
			4)如果有新进程加入高优先队列,则抢占执行新的进程,并把被抢的进程投入到原队列末尾
			
			优点:提高了系统吞吐量和缩短平均周转时间;
				多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。
				因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。
		
		5.高响应比优先调度算法HRRN
			1)HRRN为每个作业引入动态优先权，使作业的优先级随着等待时间的增加而以速率a提高
			2)优先权 =（等待时间+要求服务时间)/要求服务时间= 响应时间 / 要求服务时间
			3)什么时候计算各进程的响应比优先权？(作业完成时、新作业产生时（抢占、非抢占）、时间片完成时、进程阻塞时)
			
		6.优先级调度 
			1)静态优先权:
				创建时确定优先权 整个生命周期不改变
			2)动态优先权
				进程创建时赋一个优先权初值，运行期间动态调整其权值。具有可防止一个进程长期垄断或长期等待 CPU 的优点。
					比如: CPU使用时间;进行IO操作后增加优先级;进程等待时间越长优先级越大

