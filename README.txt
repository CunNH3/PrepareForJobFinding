12.1 https://www.nowcoder.com/discuss/571830  	未完成
12.2 https://www.nowcoder.com/discuss/574278	未开始
12.3
▲ 38 HashMap 与 ConcurrentHashMap 的实现原理是怎样的？ConcurrentHashMap 是如何保证线程安全的？ 	√
▲ 27 volatile 关键字解决了什么问题，它的实现原理是什么？										√						   
▲ 26 Java 中垃圾回收机制中如何判断对象需要回收？常见的 GC 回收算法有哪些？							
▲ 26 synchronized 关键字底层是如何实现的？它与 Lock 相比优缺点分别是什么？
▲ 24 简述 JVM 的内存模型 JVM 内存是如何对应到操作系统内存的？
▲ 20 集合类中的 List 和 Map 的线程安全版本是什么，如何保证线程安全的？
▲ 15 String 类能不能被继承？为什么？
▲ 14 Java 线程和操作系统的线程是怎么对应的？Java线程是怎样进行调度的?
▲ 11 简述 BIO, NIO, AIO 的区别
▲ 11 实现单例设计模式（懒汉，饿汉）
▲ 10 == 和 equals() 的区别？																	√
▲ 8 简述 Spring AOP 的原理
▲ 6 简述 Synchronized，Volatile，可重入锁的不同使用场景及优缺点
▲ 2 简述 Java 的 happen before 原则																
▲ 1 SpringBoot 是如何进行自动配置的？


Java基础

1. 8种基本数据类型和长度
	bool	1B	true or false
	byte	1B	-128 ~ 127
	short	2B	-32768~32767  -2^(n-1) ~ 2^(n-1)-1
	char	2B	0~65535
	int		4B	-2147483648~2147483647 -2^31 ~ 2^31-1
	float	4B 	-3.4E38~3.4E38
	long	8B	-9223372036854775808 ~ 9223372036854775807
	double	8B	-1.7E308~1.7E308

		
2. Object类的方法
	1. equals() 方法
		1)equals默认是比较对象地址是否相同 如果是同一个对象返回true
		2)重写判断内容是否相同: 同一个类的对象/成员变量都相同
		3)满足的性质: x.equals(null) false
				自反性: 非空x x.equals(x) true
				对称性: x,y非空 x.equals(y) 同时 y.equals(x)为true
				传递性：x.equals(y) 返回 true，y.equals(z) 返回 true，x.equals(z) 也应该返回 true
				一致性：如果 x 和 y 引用的对象没有发生变化，反复调用 x.equals(y) 应该返回相同的结果
	2. getClass() 方法
	3. hashCode() 方法
	4. finalize() 方法
	5. clone() 方法
	6. toString() 方法

Java容器
1. ArrayList
	扩容:
		一开始默认为容量为10 只有在add的时候才进行初始化 到11是才开始扩容
		newCapacity = oldCapacity + (oldCapacity >> 1) 每次扩容为原来的1.5倍
		System.arraycopy(elementData, index, elementData, index + 1, size - index) 函数进行拷贝
		并不会自动锁容,但是可以调用trimToSize()方法手动缩容
		
2. hashmap的内容
	怎么实现的:
		数组+链表 JDK1.8有改变,当链表长度大于8并且数组的bin超过64时,会将链表转化为红黑树 key value键值对
	原理:
	hash操作
		1.8之后 用hash值的前16位和后16位做异或增大扰动性,就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。
		而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来
		主要是高位不同, 低位相同导致的hash冲突. 因为hashmap的数组长度有限,防止一直mod取的低位数字
		return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
	put操作
		经过hash = key & (2^n-1) 定位到数组位置
			如果数组位置没有元素就直接插入
			如果定位到的数组位置有元素,遍历这个元素为头结点的链表依次和插入的key比较(equals),如果key相同则覆盖;
				不相同,判断p是否是一个树节点:是树节点就调用红黑树的putTreeVal将元素插入;是链表的话就遍历链表(插入的链表尾部)
		对应扩容, 转为红黑树
	resize
	get
	版本1.8之前之后
	多线程:

3. HashMap的多线程安全问题
		JDK1.7 头插法
		1) 扩容造成死循环
			JDK1.7采用每个桶里的链表采用头插法;
				假设有两个线程,同时扩容时对同一个桶里的链表A->B->C进行rehash并且transfer
				假设A,B Rehash完还留在当前位置,对于线程1来说 此时指针指向A next指向B, 线程1刚好挂起
				线程2按A->B->C顺序开始transfer, 由于采用头插法, A rehash留在原地, B rehash完要插在A前面, C rehash完插到了当前位置+扩容前的容量的位置
				线程2完成操作之后内存里,当前链表顺序为B->A
				此时线程1获得了时间片, 从当前指向A的指针开始rehash操作, A rehash完之后,头插到了当前链表也就是B之前 next指向B
				这个时候形成了死循环B指向A, A又指向了B
		2) 扩容造成数据丢失
			假设某个桶有一个链表A->B->C 两个线程对链表进行rehash和transfer
			线程1的指针指向A 变量next指向B 刚好在此时线程1进行了挂起
			线程2完成了所有的操作 此时因为头插法在一个桶里C->A,  B被分到另一个桶 修改了B的next B.next==null
			线程1获得了时间片,开始操作指针指向了A, A完成了rehash留在了原地, 
				next指向B, B rehash完transfer到了新的桶 因为线程2的操作B.next==null 这时候C就丢失了 
				在内存里面新的桶里面已经有一个B了,B采用头插法插入新的桶会指向自己形成死循环
			
		JDK 1.8 采用尾插法 不会再出现上面的死循环问题
		1)put的时候, 会出现数据丢失的情况
			假设两个线程 同时插入两个hash值一样的元素到同一个桶的时候
			假设线程1 判断了这个桶为null 正打算直接插入元素的时候, 挂起了 
			线程2直接将它的元素插入了这个桶所在的链表
			而后线程1回来 根据之前遍历得到的指针 直接覆盖了这个线程1插入的元素
		
		2)put和get并发时，可能导致get为null
			线程1执行put时, 因为元素个数超出threshold而导致rehash
			线程2此时执行get,有可能导致这个问题。

4. ConcurrentHashMap的实现
		JDK1.7
			Segment
				Segment是JDK1.7中ConcurrentHashMap的核心设计，通过引入分段达成提高并行处理度的效果。
				Segment继承了ReentrantLock并实现了序列化接口，说明Segment的锁是可重入的。
			HashEntry
				Segment中的元素是以HashEntry的形式存放在链表数组中的，其结构与普通HashMap的HashEntry基本一致，
				不同的是Segment的HashEntry，其value由volatile修饰，以支持内存可见性，即写操作对其他读线程即时可见。
			get方法
				根据key获取value时，由于1.7中需要两次Hash过程，第一次需要定位到Segment；第二次需要定位到Segment中的桶下标。
				在第二次查找具体元素时，首先对count做了非零判断，由于count是volatile修饰的，put、remove等操作会更新count的值，
				所以当竞争发生的时候，volatile的语义可以保证写操作在读操作之前，也就保证了写操作对后续的读操作都是可见的，
				这样后面get的后续操作就可以拿到完整的元素内容
			put方法
				put操作也涉及2次hash定位过程，但是比get操作多了是否扩容、rehash等过程
			
        JDK1.8
			put方法:
				先判断key与value是否为空。与HashMap不同，ConcurrentHashMap不允许null作为key或value，为什么这样设计? 
				因为ConcurrentHashmap是支持并发,当通过get(k)获取对应的value,
					如果获取到的是null时,无法判断它是put(k,v)的时候value为null，还是这个key从来没有做过映射。
					HashMap是非并发的，可以通过contains(key)来做这个判断。而支持并发的Map在调用m.contains（key）和m.get(key)，可能已经不同了；
				1) CAS用于当桶为空时，使用cas尝试加入新的桶头结点
				2) synchronized用于桶不为空时，向链表或树中put结点的情形
				
			get方法:
				当key为null的时候回抛出NullPointerException的异常
				get操作通过首先计算key的hash值来确定该元素放在数组的哪个位置,判断table是否为空且table长度大于0且下标不为空
				然后遍历该位置的所有节点,如果均无法定位到key则返回null
			
			resize方法:
				当需要扩容的时候，调用的时候tryPresize方法
				在tryPresize方法中，并没有加锁，允许多个线程进入，如果数组正在扩张，则当前线程也去帮助扩容。
				值得注意的是，复制之后的新链表不是旧链表的绝对倒序;
				在扩容的时候每个线程都有处理的步长,最少为16,在这个步长范围内的数组节点只有自己一个线程来处理.
				整个操作是在持有段锁的情况下执行
				
		区别比较
		1) JDK1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点）
		2) JDK1.8版本的数据结构变得更加简单，使得操作也更加清晰流畅，
			因为已经使用synchronized来进行同步，所以不需要分段锁的概念，也就不需要Segment这种数据结构了，由于粒度的降低，实现的复杂度也增加了
		3) JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表
		4) JDK1.8为什么使用内置锁synchronized来代替重入锁ReentrantLock?
			因为粒度降低了，在相对而言的低粒度加锁方式，synchronized并不比ReentrantLock差，在粗粒度加锁中ReentrantLock可能通过Condition来控制各个低粒度的边界
			在大量的数据操作下，对于JVM的内存压力，基于API的ReentrantLock会产生更多的内存开销。
		
5. HashMap 与 ConcurrentHashMap 的实现原理是怎样的？ConcurrentHashMap 是如何保证线程安全的？
	HashMap: 数组 + 链表 元素的HashCode经过扰动函数之后, 映射到数组的索引, 相同hash但是key的元素在数组的同一个位置使用尾插法增长链表
			1.8 链表的长度超过8时, 先做数组扩容避免树形化 1,当数组的长度超过64时,会将链表转化为红黑树 
	ConcurrentHashMap
		Hashtable这个结构虽然线程安全,但是效率不高,因为每个操作都是用了synchronized同步块,导致每次只有一个线程能操作数据
		JDK1.7
        采用分段锁,一个ConcurrentHashMap包含Segment数组, 每个Segement包含一个hashEntry数组。
        其中hashEntry是一个链表结构元素，而Segment继承ReentrantLock,是一种可重入锁。
        调用put修改hashEntry数组时，要获得对应的Segment锁。
        调用get读取hashEntry数组时，无需上锁。volatile修饰共享变量保证内存可见性，不会读取过期数据。
        
        JDK1.8 
		采用数组+链表/红黑树结构实现。
		通过CAS和Sychronized保证并发安全。
		Synchronized只锁定当前链表||红黑树首节点。
		Hash不冲突，就不会产生并发。进一步缩小锁的粒度。
			
		
Java 多线程

1. volatile 关键字解决了什么问题, 它的实现原理是什么?
	


数据结构与算法

1. 数组，链表插入性能对比
	对于数组,根据索引获得插入位置的时间复杂度是O(1) 
	但是插入数据时需要移动数据 
		在数组头插入 最坏复杂度是O(n) 
		在数组末尾插入 最好O(1)
		平均复杂度O(n)
	对于链表 内存地址不连续 通过指针/引用找到下个节点的位置
		查找数据插入位置所需要的时间
			最好情况是在链表头 O(1)
			最差情况是在链表尾找到O(n)
			平均复杂度O(n)
		但是插入数据很简单 只需要O(1)
		

2. bloom filter 布隆过滤器
	是一种数据结构,用来判某样东西一定不存在或者可能存在,用来检测一个元素是否在一个集合中更高效,占用小,
	优点是空间效率和查找效率远超普通的set map数据结构, 
	缺点:	返回的结果是概率性的,不是确切的 可能会判断失误
	结构:	一个很长的bit二进制数组bitmap + 一系列随机映射hash函数组成
	应用: 	黑名单系统, 垃圾邮件过滤系统, 爬虫网址判重系统 
			尤其在数据量上亿的时候 数据库承受不住
	原理:	bitmap的长度设为m k个互相独立的哈希函数 
			每个hash函数都把输入元素 映射到[0, m-1] 上 得到k个数 将k个数对应到bitmap上标记为1
			判断时:计算输入元素的k个数 
				如果bitmap中的这k个数对应的bit有一个不为 1 说明这个元素不在集合中
				如果全为 1 说明有一定概率在集合中 不能完全确定 
			错误率和bitmap的长度m 元素个数n hash函数个数k有关
	概率: https://www.zhihu.com/search?type=content&q=%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%20%E6%A6%82%E7%8E%87%E8%AE%A1%E7%AE%97
		对于特定位 没有被置为1的概率(1 - 1/m) k个函数之后仍然为0的概率(1-1/m)^k
		对于n个元素输入之后仍然为0的概率(1-1/m)^(kn) 为1的概率就是(1 - (1-1/m)^(kn)); e = lim(1+1/n)^n , n->无穷
		假设某个元素不在集合里 但是算出的k个位置都为1的概率就是 (1 - (1-1/m)^(kn) = (1 - e^(-kn/m))^k
		错误率最小 False positive k = (m/n)*ln2

3. b+ tree 和b tree 区别
	为了减少硬盘索引的读取次数 不采用二叉搜索树 而是多路平衡树,减少树的高度 高度小磁盘读写次数少,提升了性能
	B 树 多路平衡查找树 参数: m阶
		1. 根节点至少有两个孩子, 除非他是叶子节点
		2. 每个中间节点都包含 k-1 个元素 和 k个分支 其中 ceil(m/2) <= k <= m
		3. 每个叶子节点都包含 k-1 个元素,并且叶子节点不包含任何关键字信息 即为null 其中 ceil(m/2) <= k <= m
		4. 每个非终端结点中包含有n个关键字信息： (P1，K1，P2，K2，P3，......，Kn，Pn+1)。其中：
			a)   Ki (i=1...n)为关键字，且关键字按顺序升序排序K_(i-1)< K_i。 
			b)   Pi为指向子树根的接点，且指针P(i)指向子树种所有结点的关键字均小于Ki，但都大于K(i-1)。 
			c)   关键字的个数n必须满足： [ceil(m / 2) - 1] <= n <= m-1。
		操作: 插入操作的时候, 可能会向上分裂; 删除操作的时候可能会需要向左或者向右借节点 合并再删除
		
	B+树 m阶
		1. 有k个子树的中间节点包含有k个关键字(B树有k-1个关键字,非根节点元素范围 ceil(m/2) <= k <= m-1
		2. 所有叶子节点包含了全部关键字的信息,叶子节点本身依靠关键字大小排序
		3. 所有的非终端节点都可以看做是索引部分, 节点中仅包含子树根节点中最大(最小)关键字
		4. 叶子节点之间有指针
	B+树 优势
		1. 单一节点存储更多地元素 使得查询的IO次数更少
			因为B树不管叶子节点还是非叶子节点，都会保存数据, 这样导致在非叶子节点中能保存的指针数量变少
			指针少树的高度会增加,导致IO变多,性能变低
		2. 所有的查询都要查找到叶子节点, 查询性能稳定
		3. 所有叶子节点形成有序列表,便于范围查询
	

	
5. top - k小元素

6. 红黑树

7. KMP

8. 排序 堆排序



设计模式
1.单例模式
	定义:单例模式是指在内存中只会创建且仅创建一次对象的设计模式。
		 在程序中多次使用同一个对象且作用相同时，为了防止频繁地创建对象使得内存飙升.
		 单例模式可以让程序仅在内存中创建一个对象，让所有需要调用的地方都共享这一单例对象。
	类型:
		懒汉式: 在真正需要的时候比如调用的时候才去创建该类对象
				比如说一个对象使用频率不高,占用内存很大的时候
		饿汉式: 在类加载的时候就直接创建该单例对象
	写法:
		public class Singleton {	
			private static volatile Singleton singleton;
			private Singleton(){}
			public static Singleton getInstance() {
				if (singleton == null) {  // 线程A和线程B同时看到singleton = null，如果不为null，则直接返回singleton
					synchronized(Singleton.class) { // 线程A或线程B获得该锁进行初始化
						if (singleton == null) { // 其中一个线程进入该分支，另外一个线程则不会进入该分支
							singleton = new Singleton();
						}
					}
				}
				return singleton;
			}
		}
	双重校验锁DCL解释:
		1. 懒汉模式: 需要的时候才创建
		2. synchronized 加锁 为了并发 防止同时创建对象
		3. 双重检验 - 判断是否为null 每次获取对象都要获取锁,并发性能比较差;
			如果不是null的话直接得到对象,解决了并发安全+性能低效问题
		4. volatile 防止指令重排
			JVM内存分配:
				1)为singleton分配内存空间
				2)初始化singleton对象
				3)将singleton指向分配好的内存空间
			JVM在保证最终结果正确的情况下，可以不按照程序编码的顺序执行语句，尽可能提高程序的性能
			第2, 3步有可能发生重排, 1-3-2导致虽然此时singleton对象已经指向了分配好的内存空间,不为null
				但是还没有初始化,导致空指针异常
				
				

数据库
关系型数据库（主要为 Mysql）

简述关系型数据库与菲关系形数据库的区别与联系
简述数据库的事务
数据库三范式
分别说一下范式和反范式的优缺点
Mysql 数据库索引。B+ 树和 B 树的区别
为什么 B+ 树比 B 树更适合应用于数据库索引，除了数据库索引，还有什么地方用到了（操作系统的文件索引）
聚簇索引和非聚簇索引
前缀索引和覆盖索引
介绍一下数据库的事务
Mysql 有哪些隔离级别
Mysql 什么情况会造成脏读、可重复度、幻读？如何解决
Mysql 在可重复度的隔离级别下会不会有幻读的情况，为什么？
Mysql 事务是如何实现的
Binlog 和 Redo log 的区别是什么，分别是什么用？
谈一谈 MVCC 多版本并发控制
Innodb 和 MyISAM 的区别是什么
Innodb 的默认加锁方式是什么，是怎么实现的
如何高效处理大库 DDL
Mysql 索引重建
对于多列索引，哪些情况下能用到索引，哪些情况用不到索引
为什么使用数据库索引可以提高效率，在什么情况下会用不到数据库索引？
共享锁和排他锁的使用场景，
关系型数据库和非关系数据库的优缺点
Mysql 什么情况会造成慢查，如何查看慢查询
如何处理慢查询，你一般是怎么处理慢查询的
Mysql 中 varchar 和 char 的区别
数据库外键的优缺点
有没有使用过数据库的视图
Mysql 中插入数据使用自增 id 好还是使用 uuid，为什么？
Mysql 有哪些数据类型，使用的时候有没有什么注意点
Mysql 集群有哪几种方式，分别适用于什么场景
Mysql 主从模式如何保证主从强一致性
Mysql 集群如何保证主从可用性
Mysql 读写分离有哪些解决办法

非关系型数据库
redis 的底层数据结构有哪些
redis 中的 SDS 和 C 语言中的字符串有什么区别，优点是什么
redis 中的字典是如何实现的，如何解决冲突和扩容
redis 的跳表的使用场景是什么，可以实现一下吗
redis 缓存穿透，缓存击穿，缓存雪崩，热点数据集中失效 （常问）
redis 的淘汰策略，来写一下 LRU 吧
redis 的持久化方式，RDB 和 AOF 分别的使用场景
redis 如何处理事务
redis 为什么那么快？
redis 是单线程为什么还那么快？
redis 的操作为什么是原子性的，如何保证原子性
redis 集群用过哪些方案，分别怎么做。讲一下一致性哈希
redis 什么情况下会出现性能问题，有什么处理办法？
有没有使用过 redis 的分布式锁，有什么优缺点
说一下 redis 的内存模型
说一下 redis 和 memcache 的区别
你用 redis 做过什么？（这里尽量不要讲只做过缓存，可以说一下队列，排行榜/计数器，发布/订阅）
你用过哪些非关系型数据库，都有什么特点，使用场景分别是什么（体现你技术广度的时刻到了，尽可能多说，但是不会的不要说，防止被问死）
Mongodb 相对于 Mysql 有哪些优势，底层索引使用的数据结构是什么，为什么要使用这个
Mongodb 中的分片是什么意思


计算机网络
1. TCP为什么是三次握手, 四次挥手?
	a.服务器一直处于监听状态
		第一次握手:
			主机A发送SYN=1 seq=x的数据包到服务器B, 主机B由syn=1知道, A要建立联机 ACK=0
		第二次握手:
			主机B收到请求后,要求确认联机,向A发送ACK=1 ack=x+1 | SYN=1  seq=y 
		第三次握手
			主机A发送ACK=1 ack=y+1 | seq=x+1
			主机A收到报文段, 检查sck number是否正确, 第一次的x+1 以及ACK是否为1
		ack是期望收到对面字节数据的下一个序号; seq序号是己方字节数据的第一个字节的序号,保证TCP传输的有序性,防止重复接受处理
	b.为什么三次挥手
		主机A会发送连接请求,但是没有收到确认,于是重新发送了连接请求;服务器收到了请求并且接受连接,发出确认同意建立连接,数据传输完毕正常释放;
		此时因为网络延迟,服务器收了A的第一次请求.
		如果两个挥手的话,服务会收到主机流浪在网络中的请求连接,那么服务器就会直接同意建立连接;
		而此时主机A早已关闭,服务会浪费资源
		
	c.四次挥手
		1)客户端 发送FIN = 1 seq = u 用来关闭客户端到服务器的数据传输
		我的序号是u(u就是之前传送过的所有数据的最后一个字节的序号+1)
		2)服务器收到FIN 发回一个ACK=1 seq=v ack number = u+1
		这条消息的序号是v（seq=v ，这是服务器发送消息的序号)
	d.服务器close_wait: 此时,客户端通往服务器的路断开了,客户端不能向服务器发送数据
		3) 服务器关闭与客户端的连接 发送一个FIN = 1, ACK = 1, seq= w, ack number = u + 1
			这中间服务器可能又继续发送了一些数据，可能是v+1 也可能发送了更多，所以设置为w
			ACK=1，ack=u+1，因为客户端已经不能发送数据了，服务器期望收到的序号永远都是最后一个序号+1，也就是u+1
		4)客户端发回ACK报文确认, ACK=1 ack=w+1 seq=u+1并将确认序号+1
	e.客户端Time_wait:等待2MSL报文最大生存时间之后关闭
			确保最后一个确认报文到达服务器. 如果B没有收到A的确认报文, 就会重新发送确认报文
				消息发出来谁知道别人收没收到，所以还需要一个确认
			让本连接持续时间段内产生的报文都从网络消失,不影响下一个新的连接请求报文
	f.为什么四次挥手:
		关闭连接时, Serve端收到FIN报文时, 很可能不会立即断开SOCKET,所以先回复一个ACK表示知道了
			服务器还有数据要发,和打电话一样,你说完了但是我还没有说完
		只有等到Serve端将报文都发送完时,服务器才会发送FIN报文,表明数据都传送完了


2. HTTPS 和 HTTP 的区别
	1)HTTP（超文本传输协议）的基础上再加一层TLS（传输层安全性协议）或者SSL（安全套接层）
		HTTP协议运行在TCP之上，所有传输的内容都是明文，HTTPS运行在SSL/TLS之上，SSL/TLS运行在TCP之上，所有传输的内容都经过加密的。
		HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源
	2)HTTPS 用非对称加密传输对称加密钥匙,非对称加密的缺点就是运算速度非常慢
	3)HTTP和HTTPS使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。
	4)HTTPS可以有效的防止运营商劫持，解决了防劫持的一个大问题。
	
3. HTTPS加密过程？对称加密非对称加密？
	a.对称加密: 加密和解密的密钥是一样的
		AES 加密函数为E 密文=E(明文, 密钥)
			解密函数为D 明文=D(密文, 密钥)
		解密过程仍为10轮，每一轮的操作是加密操作的逆操作。由于AES的4个轮操作都是可逆的，
		因此，解密操作的一轮就是顺序执行逆行移位、逆字节代换、轮密钥加和逆列混合。同加密操作类似，最后一轮不执行逆列混合，在第1轮解密之前，要执行1次密钥加操作
	
	b.非对称加密: 加密和解密的密钥是不一样的 
		RSA基于大数分解
		https://zh.m.wikipedia.org/zh-sg/RSA%E5%8A%A0%E5%AF%86%E6%BC%94%E7%AE%97%E6%B3%95

		
	c.CA: Certificate Authority
		负责对证书进行签名 CA用自己私钥进行签名,客户端用公钥解密验证Hash值是否一致
	d.加密过程:
		1)客户端发起一个http请求(三次握手)，连接到服务器的443端口 
			HTTP协议
		2)服务端把自己的信息以数字证书的形式返回给客户端(证书内容有密钥公钥，网站地址，证书颁发机构，失效日期等)。
			证书中有一个公钥来加密信息，私钥由服务器持有。
		3)客户端验证证书的合法性客户端验证证书是否合法，如果不合法则提示告警
			客户端收到服务器的响应后会先验证证书的合法性（证书中包含的地址与正在访问的地址是否一致，证书是否过期）。
		4)生成随机密码,用RSA签名
			如果验证通过，或用户接受了不受信任的证书，浏览器就会生成一个随机的对称密钥(session key)
			并用公钥加密，让服务端用私钥解密，解密后就用这个对称密钥进行传输了，并且能够说明服务端确实是私钥的持有者。
		5)生成对称加密算法
			验证完服务端身份后，客户端生成一个对称加密的算法和对应密钥，以公钥加密之后发送给服务端。
			此时被黑客截获也没用，因为只有服务端的私钥才可以对其进行解密。之后客户端与服务端可以用这个对称加密算法来加密和解密通信内容了。

4. cookie与session
	cookie
		1)http是无状态的协议，客户每次读取web页面时，服务器都打开新的会话，而且服务器也不会自动维护客户的上下文信息
		2)Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。
		3)客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。
		4)服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。
		5)session id存放在cookie中, 加密
		6)第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie 里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，
		7)如果客户端的浏览器禁用了 Cookie 会使用一种叫做URL重写的技术来进行会话跟踪，
			即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数，服务端据此来识别用户。
	session
		1)Session是一种记录客户状态的机制，不同于Cookie的是Cookie保存在客户端浏览器中，而Session保存在服务器上。
		2)客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上,这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。
	区别:
		Session工作在Server中；Cookie工作在Client
		二者均工作在内存中，也可以做持久化
		

DNS劫持是什么，怎么解决
TCP 和 UDP 的区别，为什么头部长度不一样？
简述从输入网址到浏览器显示的过程
TCP 如何保障数据包有效


操作系统
1. 进程, 线程, 协程
	进程
	- 进程是操作系统进行资源分配的基本单位, 进程拥有自己的资源空间,包含若干线程
	- 进程是操作系统结构的基础
	- 系统进行资源分配和调度的独立单位
	线程
	- 线程是调度的基本单位, 线程的调度比进程要快
	- 进程中独立运行的子任务
		线程的创建和切换开销比进程小
		进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率
		终止一个线程要比终止一个进程花费的时间少 线程间切换也比进程间切换要花费少
		线程提高了不同执行程序之间的通信效率,线程在同一个进程中的线程共享内存和文件
	协程
		进程和线程受os调度算法的影响,无法精确控制
		协程（Coroutine）是一种轻量级的用户态线程，实现的是非抢占式的调度，即由当前协程切换到其他协程由当前协程来控制
			协程执行不下去的时候,自己通知协程池调度器,主动让出CPU
			切换这个协程的CPU上下文把CPU的运行权交给下一个协程
		优点:
			协程更加轻量，创建成本更小，降低了内存消耗
			协作式的用户态调度器，减少了 CPU 上下文切换的开销，提高了 CPU 缓存命中率。
			进程 / 线程的切换需要在内核完成，而协程不需要，协程通过用户态栈实现，更加轻量，速度更快。在重 I/O 的程序里有很大的优势
			减少同步加锁，整体上提高了性能。协程方案基于事件循环方案，减少了同步加锁的频率。
				但若存在竞争，并不能保证临界区，因此该上锁的地方仍需要加上协程锁
			可以按照同步思维写异步代码，即用同步的逻辑，写由协程调度的回调
		缺点:
			在协程执行中不能有阻塞操作，否则整个线程被阻塞(协程是语言级别的，线程，进程属于操作系统级别)
			需要特别关注全局变量、对象引用的使用
			协程可以处理 IO 密集型程序的效率问题，但是处理 CPU 密集型不是它的长处
		用处:
			高性能计算，牺牲公平性换取吞吐
			
2. 进程通信
	管道
		是指用于连接一个读进程和一个写进程以实现他们之间通信的一个共享文件——.pipe文件。
		写进程向管道以字符流写入数据，读进程从管道中接收输出。管道必须提供同步、互斥并能确定对方存在的方法
		netstat -tulnp | grep 8080
		匿名管道 
			单向 第一个的输出作为第二个的输入
		命名管道
			mkfifo  test 
			双向的 一个写了之后第二个去拿 类似缓存
			效率低下 只有拿完才返回
		不适合频繁通信的进程
	共享内存
		通过一片共享区域进行读写操作实现进程之间的信息交换。在操作时需要使用同步互斥工具(PV操作)。共享存储分为低级的基于数据结构的共享和高级的基于存储区的共享
	信号量机制
		信号量的本质就是计数器，在访问临界资源并进入临界区时，使用os提供的PV操作对计数器进行修改
	消息队列
	消息传递		
		利用os提供的发送原语和接收原语进行交换
		消息传递分为直接通信和间接通信。
			直接通信采用进程间发消息的方式，将消息挂在接收进程的消息缓冲队列上，接收进程从该队列上取得消息。
			间接通信则将消息发送到某个中间实体上，称其为信箱。

	Socket
		接字也是一种进程间通信机制，与其它通信机制不同的是，它可用于不同机器间的进程通信
		
3. 线程状态, 线程上下文切换？
	Java	线程状态 抢占式调度
	1.新建状态
		new完一个线程对象之后, 处于新建状态
	2.就绪状态
		调用start()方法之后, 该线程就进入就绪状态(就绪队列中) 等待JVM里线程调度器的调度
	3.运行状态
		执行run() 此时线程处于运行状态. 可以转换成 -> 阻塞状态/就绪状态/死亡状态
	4.阻塞状态
	如果一个线程执行了sleep睡眠 suspend挂起等方法 失去所占资源之后,该线程就从运行状态转化为阻塞状态
	5.死亡状态
		完成任务或者终止条件发生
	一些方法
	sleep(): 让当前线程睡眠 不会释放任何锁
	yield(): 让出时间片给其他线程,回到就绪状态. 
			 线程调度重新选择就绪态的线程分配CPU资源
	join():  暂停当前线程,等待被调用的线程指向结束后再继续执行
	wait(): 让该线程处于等待状态 会释放掉CPU执行权和占用的锁
			不能自动唤醒,依靠其他线程调用notify() 或者notifyAll()方法才能被唤醒
		
4. 进程调度说说吧？讲讲进程调度算法？
	进程的数量是远多于处理器数量的,因此宏观上并行的进程在微观上往往属于分时复用.
	进程调度的本质就是怎么更好分时复用处理器资源, 包括调度策略和进程切花
	指标: 周转时间(运行时间Ts+等待时间Tw = 执行完成时间-到达时间) T
			带权周转时间(周转时间T / 执行时间Ts)
	常用调度算法:
		1.先来先服务FCFS:
			1)按照作业提交的时间先后顺序,或者进程变为就绪态的先后次序分派CPU
			2)只有当前进程执行完成或者阻塞,新的进程才获得CPU运行
			3)默认非抢占,被唤醒的作业或者进程不立即恢复执行,通常等到当前作业出让CPU
			4)有利于CPU繁忙型作业,不利于IO繁忙的进程
			5)不利于短作业进程(需要等待较长时间 但是运行时间很短 带权周转时间很大)
			
		2.短作业（进程）优先调度算法SJF（非抢占）/SPF（抢占）
			1)从后备队列中选出一个或者若干个估计运行时间最短的作业,调入内存运行
			2)平均周转时间、平均带权周转时间都有明显改善,有效的降低作业的平均等待时间，提高系统吞吐量。
			3)未考虑作业的紧迫程度，因而不能保证紧迫性作业（进程）的及时处理、
			4)对长作业的不利、长作业的周转时间明显增加。
			5)必须知道作业运行时间, 作业（进程）的长短含主观因素, 不一定真的能做到短作业优先
			
		3.时间片轮转
			1)排成一个队列,每次调度时将CPU分配给队首
			2)为每个进程分配一个固定的时间片段,时间片运转完,进行进程切换
			3)当前进程阻塞或者已经执行完成 未用完的时间片也要让出CPU
			4)响应及时, 但是没有考虑作业时间长短问题,
			5)需要考虑时间片的长度,影响比较大
			
		4.多级反馈队列调度算法
			1)设置多个就绪队列,分别赋予不同的优先级,优先权逐级降低,但是优先级越低分配的时间片越长,例如逐级加倍
			2)新进程进入内存后,加入队列1的末尾 按FCFS算法进行调度 如果队列1时间片未能执行完毕,则降低优先级加入到队列2的末尾;
				依次类推直到最后的队列,则按时间片轮转运行完毕
			3)仅当高优先级队列为空时,才调度低优先级队列的进程执行;
			4)如果有新进程加入高优先队列,则抢占执行新的进程,并把被抢的进程投入到原队列末尾
			
			优点:提高了系统吞吐量和缩短平均周转时间;
				多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。
				因而它是目前被公认的一种较好的进程调度算法，UNIX 操作系统采取的便是这种调度算法。
		
		5.高响应比优先调度算法HRRN
			1)HRRN为每个作业引入动态优先权，使作业的优先级随着等待时间的增加而以速率a提高
			2)优先权 =（等待时间+要求服务时间)/要求服务时间= 响应时间 / 要求服务时间
			3)什么时候计算各进程的响应比优先权？(作业完成时、新作业产生时（抢占、非抢占）、时间片完成时、进程阻塞时)
			
		6.优先级调度 
			1)静态优先权:
				创建时确定优先权 整个生命周期不改变
			2)动态优先权
				进程创建时赋一个优先权初值，运行期间动态调整其权值。具有可防止一个进程长期垄断或长期等待 CPU 的优点。
					比如: CPU使用时间;进行IO操作后增加优先级;进程等待时间越长优先级越大

